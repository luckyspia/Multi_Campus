{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 영화평 감성분석\n",
    "- Tokenizer function\n",
    "- TfidfVectorzier + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/naver_movie_train_전처리완료,tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lucky\\Multi_Campus\\Workspace\\01.Machine_Learning\\07.Text Analysis\\06.Naver_Movie_sentiment(2).ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lucky/Multi_Campus/Workspace/01.Machine_Learning/07.Text%20Analysis/06.Naver_Movie_sentiment%282%29.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39m# 네이버 영화 리뷰 데이터로 검색\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lucky/Multi_Campus/Workspace/01.Machine_Learning/07.Text%20Analysis/06.Naver_Movie_sentiment%282%29.ipynb#ch0000003?line=1'>2</a>\u001b[0m train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m./data/naver_movie_train_전처리완료,tsv\u001b[39;49m\u001b[39m'\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lucky/Multi_Campus/Workspace/01.Machine_Learning/07.Text%20Analysis/06.Naver_Movie_sentiment%282%29.ipynb#ch0000003?line=2'>3</a>\u001b[0m test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m./data/naver_movie_test_전처리완료.tsv\u001b[39m\u001b[39m'\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lucky/Multi_Campus/Workspace/01.Machine_Learning/07.Text%20Analysis/06.Naver_Movie_sentiment%282%29.ipynb#ch0000003?line=3'>4</a>\u001b[0m train_df\u001b[39m.\u001b[39mshape, test_df\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:610\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=604'>605</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=605'>606</a>\u001b[0m     dialect, delimiter, delim_whitespace, engine, sep, defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=606'>607</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=607'>608</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=609'>610</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:462\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=458'>459</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=460'>461</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=461'>462</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=463'>464</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=464'>465</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:819\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=815'>816</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwds:\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=816'>817</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=818'>819</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:1050\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1045'>1046</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1046'>1047</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown engine: \u001b[39m\u001b[39m{\u001b[39;00mengine\u001b[39m}\u001b[39;00m\u001b[39m (valid options are \u001b[39m\u001b[39m{\u001b[39;00mmapping\u001b[39m.\u001b[39mkeys()\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1047'>1048</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1048'>1049</a>\u001b[0m \u001b[39m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1049'>1050</a>\u001b[0m \u001b[39mreturn\u001b[39;00m mapping[engine](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:1867\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1863'>1864</a>\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39musecols\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1865'>1866</a>\u001b[0m \u001b[39m# open handles\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1866'>1867</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open_handles(src, kwds)\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1867'>1868</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1868'>1869</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:1362\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1357'>1358</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_handles\u001b[39m(\u001b[39mself\u001b[39m, src: FilePathOrBuffer, kwds: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1358'>1359</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1359'>1360</a>\u001b[0m \u001b[39m    Let the readers open IOHanldes after they are done with their potential raises.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1360'>1361</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1361'>1362</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1362'>1363</a>\u001b[0m         src,\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1363'>1364</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1364'>1365</a>\u001b[0m         encoding\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1365'>1366</a>\u001b[0m         compression\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1366'>1367</a>\u001b[0m         memory_map\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1367'>1368</a>\u001b[0m         storage_options\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/parsers.py?line=1368'>1369</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:642\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/common.py?line=639'>640</a>\u001b[0m         errors \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/common.py?line=640'>641</a>\u001b[0m     \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/common.py?line=641'>642</a>\u001b[0m     handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/common.py?line=642'>643</a>\u001b[0m         handle,\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/common.py?line=643'>644</a>\u001b[0m         ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/common.py?line=644'>645</a>\u001b[0m         encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/common.py?line=645'>646</a>\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/common.py?line=646'>647</a>\u001b[0m         newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/common.py?line=647'>648</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/common.py?line=648'>649</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/common.py?line=649'>650</a>\u001b[0m     \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lucky/anaconda3/lib/site-packages/pandas/io/common.py?line=650'>651</a>\u001b[0m     handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/naver_movie_train_전처리완료,tsv'"
     ]
    }
   ],
   "source": [
    "# 네이버 영화 리뷰 데이터로 검색\n",
    "train_df = pd.read_csv('./data/Naver_movie_train_preprocesssed,tsv', sep='\\t')\n",
    "test_df = pd.read_csv('./data/Naver_movie_test_preprocessed.tsv', sep='\\t')\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을','ㅋㅋ','ㅠㅠ','ㅎㅎ']\n",
    "a = '은 는 이 가'.split() # stop words 추가\n",
    "stopwords.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okt_tokenizer(text):\n",
    "    morphs = okt.morphs(text, stem=True)\n",
    "    tokens = [word for word in morphs if word not in stopwords]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['열심히', '일', '당신', '주말', '엔', '여행', '떠나다', '보다', '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt_tokenizer('열심히 일한 당신 주말엔 여행을 떠나봐요.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pipeline으로 특성 변환과 분류를 동시에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dropna(how='any', inplace=True)\n",
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('TFIDF',\n",
       "                 TfidfVectorizer(tokenizer=<function okt_tokenizer at 0x000001E7D22AF8B0>)),\n",
       "                ('LR', LogisticRegression(random_state=2022))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline을 활용하면 한글이나 영문이나 동일하게 취급할 수 있음\n",
    "pipeline = Pipeline([\n",
    "    ('TFIDF', TfidfVectorizer(tokenizer=okt_tokenizer)),\n",
    "    ('LR',LogisticRegression(random_state=2022))\n",
    "])\n",
    "pipeline.fit(train_df.document, train_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.dropna(how='any', inplace=True)\n",
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8474508470508231"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(test_df.document, test_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "reviews = ['모든 국민이 봤으면 하는 영화입니다.',\n",
    "            '생각보다 지루하고 별로였네요... 보면서 좀 졸았습니다.']\n",
    "reviews = map(lambda x: re.sub('[^가-힣]',' ',x), reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    'TFIDF__ngram_range':[(1,1), (1,2)],\n",
    "    'TFIDF__max_df':[0.95, 0.98],\n",
    "    'LR__C': [1, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pipe = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "# %time grid_pipe.fit(train_df.document, train_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eval by Parameters of CountVectorizer exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12min 56s\n",
      "Wall time: 11min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('TFIDF',\n",
       "                 TfidfVectorizer(max_df=0.95, ngram_range=(1, 2),\n",
       "                                 tokenizer=<function okt_tokenizer at 0x000001E7D22AF8B0>)),\n",
       "                ('LR', LogisticRegression(random_state=2022))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('TFIDF', TfidfVectorizer(tokenizer=okt_tokenizer, max_df=0.95, ngram_range=(1,2))),\n",
    "    ('LR', LogisticRegression(random_state=2022))\n",
    "])\n",
    "%time pipeline.fit(train_df.document, train_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8619717183030982"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(test_df.document, test_df.label)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d8033f6c2facdf0c540ae24185783756312e465f81bc1a6a1c85e47e304566e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
