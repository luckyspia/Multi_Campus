{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 2022\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''경마장에 있는 말이 뛰고 있다.\n",
    "그의 말이 법이다.\n",
    "가는 말이 고와야 오는 말이 곱다.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합 생성\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'말이': 1,\n",
       " '경마장에': 2,\n",
       " '있는': 3,\n",
       " '뛰고': 4,\n",
       " '있다': 5,\n",
       " '그의': 6,\n",
       " '법이다': 7,\n",
       " '가는': 8,\n",
       " '고와야': 9,\n",
       " '오는': 10,\n",
       " '곱다': 11}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특징\n",
    "# 1. 가나다 순서가 아니고 많이 나온 단어 순서\n",
    "# 2. 1에서 부터 시작함\n",
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 집합 크기 - Keras Tokenizer의 시작 인덱스가 1이기 때문에 1을 더해주어야 함\n",
    "vocab_size = len(t.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 1, 7]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.texts_to_sequences(['그의 말이 법이다.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 1, 4, 5]\n",
      "[6, 1, 7]\n",
      "[8, 1, 9, 10, 1, 11]\n"
     ]
    }
   ],
   "source": [
    "# corpus를 encoding한 결과\n",
    "for line in text.split('\\n'):\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 1, 4, 5, 6, 1, 7, 8, 1, 9, 10, 1, 11]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.texts_to_sequences([text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3],\n",
       " [2, 3, 1],\n",
       " [2, 3, 1, 4],\n",
       " [2, 3, 1, 4, 5],\n",
       " [6, 1],\n",
       " [6, 1, 7],\n",
       " [8, 1],\n",
       " [8, 1, 9],\n",
       " [8, 1, 9, 10],\n",
       " [8, 1, 9, 10, 1],\n",
       " [8, 1, 9, 10, 1, 11]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequences.append(encoded[:i+1])\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequence 중에서 제일 길이가 긴 것\n",
    "max_len = max(len(seq) for seq in sequences)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 2, 3],\n",
       "       [0, 0, 0, 2, 3, 1],\n",
       "       [0, 0, 2, 3, 1, 4],\n",
       "       [0, 2, 3, 1, 4, 5],\n",
       "       [0, 0, 0, 0, 6, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding\n",
    "# 전체 샘플 길이를 max_len에 맞추도록 0을 추가\n",
    "# 앞쪽을 채우는 pre 옵션이 디폴트\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  0,  2,  3,  1],\n",
       "       [ 0,  0,  2,  3,  1,  4],\n",
       "       [ 0,  2,  3,  1,  4,  5],\n",
       "       [ 0,  0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  6,  1,  7],\n",
       "       [ 0,  0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  0,  8,  1,  9],\n",
       "       [ 0,  0,  8,  1,  9, 10],\n",
       "       [ 0,  8,  1,  9, 10,  1],\n",
       "       [ 8,  1,  9, 10,  1, 11]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data set\n",
    "- sequence가 생성되는 과정에 따라, 앞선 내용을 학습해 마지막 토큰을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11, 5), (11,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X, y\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = to_categorical(y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling\n",
    "- Embedding\n",
    "- Simple RNN\n",
    "- Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 5, 4)              48        \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                1184      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                396       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,628\n",
      "Trainable params: 1,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "# Embedding=4, SimpleRNN=32\n",
    "# Embedding vector의 갯수가 RNN layer에서 feature 갯수\n",
    "model = Sequential([ \n",
    "    Embedding(vocab_size, 4, input_length=max_len-1),\n",
    "    SimpleRNN(32),                                      # activation='tanh' 는 디폴트 옵션\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X, Y, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['accuracy'][-1]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'경마장에 있는 말이 뛰고'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from my_util import sentence_generation\n",
    "sentence_generation(model, t, max_len, '경마장에', 3)   # 모델, 토크나이저, maxlen, 현재 단어, 반복 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'가는 말이 고와야 오는 말이 곱다'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(model, t, max_len, '가는', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Embedding vector: 2, RNN unit: 24\n",
      "정확도: 0.8182\n",
      "경마장에 말이 말이 오는 말이\n",
      "그의 말이 법이다\n",
      "가는 말이 법이다 오는 말이 곱다\n",
      "\n",
      "=============================================\n",
      "Embedding vector: 2, RNN unit: 32\n",
      "정확도: 0.8182\n",
      "경마장에 말이 법이다 오는 말이\n",
      "그의 말이 고와야\n",
      "가는 말이 고와야 오는 말이 곱다\n",
      "\n",
      "=============================================\n",
      "Embedding vector: 2, RNN unit: 48\n",
      "정확도: 0.9091\n",
      "경마장에 말이 고와야 오는 말이\n",
      "그의 말이 법이다\n",
      "가는 말이 고와야 오는 말이 곱다\n",
      "\n",
      "=============================================\n",
      "Embedding vector: 4, RNN unit: 24\n",
      "정확도: 0.8182\n",
      "경마장에 말이 말이 오는 말이\n",
      "그의 말이 법이다\n",
      "가는 말이 법이다 오는 말이 곱다\n",
      "\n",
      "=============================================\n",
      "Embedding vector: 4, RNN unit: 32\n",
      "정확도: 1.0000\n",
      "경마장에 있는 말이 뛰고 있다\n",
      "그의 말이 법이다\n",
      "가는 말이 고와야 오는 말이 곱다\n",
      "\n",
      "=============================================\n",
      "Embedding vector: 4, RNN unit: 48\n",
      "정확도: 0.9091\n",
      "경마장에 말이 고와야 오는 말이\n",
      "그의 말이 법이다\n",
      "가는 말이 고와야 오는 말이 곱다\n",
      "\n",
      "=============================================\n",
      "Embedding vector: 6, RNN unit: 24\n",
      "정확도: 1.0000\n",
      "경마장에 있는 말이 뛰고 있다\n",
      "그의 말이 법이다\n",
      "가는 말이 고와야 오는 말이 곱다\n",
      "\n",
      "=============================================\n",
      "Embedding vector: 6, RNN unit: 32\n",
      "정확도: 1.0000\n",
      "경마장에 있는 말이 뛰고 있다\n",
      "그의 말이 법이다\n",
      "가는 말이 고와야 오는 말이 곱다\n",
      "\n",
      "=============================================\n",
      "Embedding vector: 6, RNN unit: 48\n",
      "정확도: 1.0000\n",
      "경마장에 있는 말이 뛰고 있다\n",
      "그의 말이 법이다\n",
      "가는 말이 고와야 오는 말이 곱다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_embed in [2,4,6]:\n",
    "    for n_unit in [24,32,48]:\n",
    "        model = Sequential([ \n",
    "            Embedding(vocab_size, n_embed, input_length=max_len-1),\n",
    "            SimpleRNN(n_unit),\n",
    "            Dense(vocab_size, activation='softmax')\n",
    "        ])\n",
    "        model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "        hist = model.fit(X, Y, epochs=200, verbose=0)\n",
    "        print('=============================================')\n",
    "        print(f'Embedding vector: {n_embed}, RNN unit: {n_unit}')\n",
    "        print(f\"정확도: {hist.history['accuracy'][-1]:.4f}\")\n",
    "        print(sentence_generation(model, t, max_len, '경마장에', 4))\n",
    "        print(sentence_generation(model, t, max_len, '그의', 2))\n",
    "        print(sentence_generation(model, t, max_len, '가는', 5))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68756eb6c044f31c46e3e1f38723aea1f0146198488dd3d60c0e4241eb6f7dd0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
